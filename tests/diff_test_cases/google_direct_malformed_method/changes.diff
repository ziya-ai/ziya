--- a/app/agents/wrappers/google_direct.py
+++ b/app/agents/wrappers/google_direct.py
@@ -3,12 +3,9 @@
 import asyncio
 from typing import List, Dict, Optional, AsyncIterator, Any, Any
 from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, AIMessage
 from langchain_core.tools import BaseTool
-from google import genai
-from google.genai import types
+from google import generativeai as genai
+from google.generativeai import types
 from app.utils.logging_utils import logger
 from app.mcp.manager import get_mcp_manager
-from app.config.models_config import TOOL_SENTINEL_OPEN, TOOL_SENTINEL_CLOSE
-from app.mcp.tools import parse_tool_call
 
 def _extract_text_from_mcp_result(result: Any) -> str:
     """Extracts the text content from a structured MCP tool result."""
@@ -49,7 +46,6 @@
         self.model_name = model_name
         self.temperature = temperature
         self.max_output_tokens = max_output_tokens
-        self.client = genai.Client()  # Use the new SDK client
         self.mcp_manager = get_mcp_manager()
 
     def _convert_langchain_tools_to_google(self, tools: List[BaseTool]) -> List[types.Tool]:
@@ -106,99 +102,83 @@
         """
         Streams responses from the Google Gemini model, handling native tool calls correctly.
         """
         tools = kwargs.get("tools", [])
         google_tools = self._convert_langchain_tools_to_google(tools)
         history, system_instruction = self._convert_messages_to_google_format(messages)
 
-        text_buffer = ""
+        model = genai.GenerativeModel(
+            self.model_name,
+            system_instruction=system_instruction
+        )
 
-        try:
-            # Use the new SDK's streaming method
-            for chunk in self.client.models.generate_content_stream(
-                model=self.model_name,
-                contents=history,
-                config=types.GenerateContentConfig(
+        # The main loop for handling multi-turn tool calls
+        while True:
+            logger.info("Calling Google model with history...")
+            try:
+                response = await model.generate_content_async(
+                    history,
+                    generation_config=types.GenerationConfig(
+                        temperature=self.temperature,
+                        max_output_tokens=self.max_output_tokens,
+                    ),
+                    tools=google_tools if google_tools else None,
+                    stream=True
+                )
+            except Exception as e:
+                error_message = f"Google API Error ({type(e).__name__}): {str(e)}"
+                logger.error(error_message, exc_info=True)
+                yield {"type": "error", "content": error_message}
+                return
+
+            tool_calls = []
+            model_response_parts = []
+            
+            async for chunk in response:
+                if chunk.parts:
+                    for part in chunk.parts:
+                        if part.text:
+                            yield {"type": "text", "content": part.text}
+                        if part.function_call:
+                            tool_calls.append(part.function_call)
+                
+                if chunk.candidates:
+                    for candidate in chunk.candidates:
+                        if candidate.content and candidate.content.parts:
+                            model_response_parts.extend(candidate.content.parts)
+
+            if not tool_calls:
+                logger.info("No tool calls from model. Ending loop.")
+                break
+
+            logger.info(f"Model returned {len(tool_calls)} tool call(s).")
+            history.append({'role': 'model', 'parts': model_response_parts})
+
+            tool_results = []
+            for tool_call in tool_calls:
+                tool_name = tool_call.name
+                tool_args = dict(tool_call.args) if hasattr(tool_call, 'args') and tool_call.args else {}
+
+                yield {"type": "tool_start", "tool_name": tool_name, "input": tool_args}
+
+                try:
+                    tool_result_obj = await self.mcp_manager.call_tool(tool_name, tool_args)
+                    tool_result_str = _extract_text_from_mcp_result(tool_result_obj)
+                    
+                    yield {"type": "tool_execution", "tool_name": tool_name, "result": tool_result_str}
+                    
+                    tool_results.append(types.Part.from_function_response(
+                        name=tool_name,
+                        response={"content": tool_result_str}
+                    ))
+                except Exception as e:
+                    error_message = f"Error executing tool {tool_name}: {e}"
+                    logger.error(error_message)
+                    yield {"type": "error", "content": error_message}
+                    tool_results.append(types.Part.from_function_response(
+                        name=tool_name,
+                        response={"error": error_message}
+                    ))
+            
+            history.append({'role': 'function', 'parts': tool_results})
 
-                    temperature=self.temperature,
-                    max_output_tokens=self.max_output_tokens,
-                    system_instruction=system_instruction.parts[0].text if system_instruction else None,
-                    tools=google_tools if google_tools else None,
-                )
-            ):
-                # Handle the actual response structure
-                if hasattr(chunk, 'candidates') and chunk.candidates:
-                    for candidate in chunk.candidates:
-                        if hasattr(candidate, 'content') and candidate.content and hasattr(candidate.content, 'parts') and candidate.content.parts:
-                            for part in candidate.content.parts:
-                                # Check for function calls
-                                if hasattr(part, 'function_call') and part.function_call:
-                                    fc = part.function_call
-                                    tool_name = fc.name
-                                    tool_args = dict(fc.args) if hasattr(fc, 'args') and fc.args else {}
-
-                                    yield {"type": "tool_start", "tool_name": tool_name, "input": tool_args}
-
-                                    # Execute the tool
-                                    try:
-                                        tool_result_obj = await self.mcp_manager.call_tool(tool_name, tool_args)
-                                        tool_result_str = _extract_text_from_mcp_result(tool_result_obj)
-                                        yield {"type": "tool_execution", "tool_name": tool_name, "result": tool_result_str}
-                                    except Exception as e:
-                                        error_message = f"Error executing tool {tool_name}: {e}"
-                                        logger.error(error_message)
-                                        yield {"type": "error", "content": error_message}
-
-                                # Handle regular text chunks
-                                elif hasattr(part, 'text') and part.text:
-                                    text_buffer += part.text
- 
-                                     # Process any complete tool calls in the buffer
-                                     while TOOL_SENTINEL_OPEN in text_buffer and TOOL_SENTINEL_CLOSE in text_buffer:
-                                         start_index = text_buffer.find(TOOL_SENTINEL_OPEN)
-                                         end_index = text_buffer.find(TOOL_SENTINEL_CLOSE) + len(TOOL_SENTINEL_CLOSE)
- 
-                                         # Yield any text that came before the tool call
-                                         if start_index > 0:
-                                             yield {"type": "text", "content": text_buffer[:start_index]}
- 
-                                         # Extract and process the tool call block
-                                         tool_call_block = text_buffer[start_index:end_index]
-                                         parsed_call = parse_tool_call(tool_call_block)
- 
-                                         if parsed_call:
-                                             tool_name = parsed_call["tool_name"]
-                                             tool_args = parsed_call["arguments"]
-                                             yield {"type": "tool_start", "tool_name": tool_name, "input": tool_args}
-                                             try:
-                                                 tool_result_obj = await self.mcp_manager.call_tool(tool_name, tool_args)
-                                                 tool_result_str = _extract_text_from_mcp_result(tool_result_obj)
-                                                 yield {"type": "tool_execution", "tool_name": tool_name, "result": tool_result_str}
-                                             except Exception as e:
-                                                 error_message = f"Error executing tool {tool_name}: {e}"
-                                                 logger.error(error_message)
-                                                 yield {"type": "error", "content": error_message}
- 
-                                         # Update the buffer to remove what we've processed
-                                         text_buffer = text_buffer[end_index:]
-                                     
-                                     # After processing complete tools, stream any remaining text
-                                     # that is NOT part of an incomplete tool call.
-                                     partial_start_index = text_buffer.find(TOOL_SENTINEL_OPEN)
-                                     if partial_start_index != -1:
-                                         if partial_start_index > 0:
-                                             yield {"type": "text", "content": text_buffer[:partial_start_index]}
-                                             text_buffer = text_buffer[partial_start_index:]
-                                     else:
-                                         if text_buffer:
-                                             yield {"type": "text", "content": text_buffer}
-                                             text_buffer = ""
- 
-             # After the loop, yield any remaining text in the buffer
-             if text_buffer:
-                 yield {"type": "text", "content": text_buffer}
-
-        except Exception as e:
-            error_message = f"Google API Error ({type(e).__name__}): {str(e)}"
-            logger.error(error_message, exc_info=True)
-            yield {"type": "error", "content": error_message}
-
     def bind(self, **kwargs):
         """Compatibility method - ignore stop sequences for Google."""
         return self
